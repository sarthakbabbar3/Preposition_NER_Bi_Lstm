{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/gpuadmin/projects/candice/AGEL/agel_backend/agel_v15/copy_editing/get_grammar_suggestions')\n",
    "from __parameters__ import word_tokenizer, sentence_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/gpuadmin/Candice/Data/data_prep_2.json','r',encoding = 'utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare NER Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import logging\n",
    "from collections import Counter\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-07 12:25:29,181 loading projection weights from w2v_all_raw_cap.txt\n",
      "2020-01-07 12:25:33,774 loaded (43350, 128) matrix from w2v_all_raw_cap.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.58 s, sys: 136 ms, total: 4.72 s\n",
      "Wall time: 4.59 s\n"
     ]
    }
   ],
   "source": [
    "%time w2v_all_caps = KeyedVectors.load_word2vec_format(\"w2v_all_raw_cap.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocab = list(w2v_all_caps.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary : 43352\n"
     ]
    }
   ],
   "source": [
    "all_vocab = ['<pad>'] + all_vocab + ['<unk>'] #adding padding and unknown words to vocab\n",
    "print('Length of vocabulary : {}'.format(len(all_vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting vocab to numbers and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2int = {tok: i for i, tok in enumerate(all_vocab)}\n",
    "int2vocab = {i: tok for i, tok in enumerate(all_vocab)}\n",
    "\n",
    "def tok2int(tokens):\n",
    "    ret = []\n",
    "    for tok in tokens:\n",
    "        temp = vocab2int[tok] if tok in vocab2int else vocab2int['<unk>']\n",
    "        ret.append(temp)\n",
    "    return ret\n",
    "\n",
    "int2tok = lambda ints : [int2vocab[item] for item in ints]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all vectors shape = (43350, 128)\n"
     ]
    }
   ],
   "source": [
    "all_vectors = w2v_all_caps.vectors\n",
    "print('all vectors shape = {}'.format(all_vectors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all vectors shape = (43352, 128)\n"
     ]
    }
   ],
   "source": [
    "#adding vector for padding at the beginning\n",
    "all_vectors = np.append(np.zeros((1,w2v_all_caps.vector_size)), all_vectors, axis=0)\n",
    "#adding vector for unknown words at the end\n",
    "all_vectors = np.append(all_vectors, np.random.random((1, w2v_all_caps.vector_size)), axis = 0)\n",
    "\n",
    "print('all vectors shape = {}'.format(all_vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_toks = [tok for item in data for tok in item['model_output']]\n",
    "label_count = Counter(all_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 621886,\n",
       "         'S-–_INS': 3773,\n",
       "         'S-to_INS_ONLY': 130,\n",
       "         'S--_INS': 3056,\n",
       "         'S-in_INS': 925,\n",
       "         'S-with_INS': 5945,\n",
       "         'S-to_INS': 2757,\n",
       "         'S-—_INS': 1537,\n",
       "         'S-of_INS': 405,\n",
       "         'B-–_INS': 40,\n",
       "         'I-–_INS': 7,\n",
       "         'E-–_INS': 40,\n",
       "         'S-of_INS_ONLY': 142,\n",
       "         'S-–_INS_ONLY': 266,\n",
       "         'S-because_INS': 1131,\n",
       "         'S-after_INS': 1382,\n",
       "         'B-to_INS': 13,\n",
       "         'E-to_INS': 13,\n",
       "         'B-of_INS': 9,\n",
       "         'E-of_INS': 9,\n",
       "         'I-to_INS': 2,\n",
       "         'I-of_INS': 3})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 23\n"
     ]
    }
   ],
   "source": [
    "all_labels = ['<pad>'] + list(label_count.keys())\n",
    "print('Number of labels = {}'.format(len(all_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'O',\n",
       " 'S-–_INS',\n",
       " 'S-to_INS_ONLY',\n",
       " 'S--_INS',\n",
       " 'S-in_INS',\n",
       " 'S-with_INS',\n",
       " 'S-to_INS',\n",
       " 'S-—_INS',\n",
       " 'S-of_INS',\n",
       " 'B-–_INS',\n",
       " 'I-–_INS',\n",
       " 'E-–_INS',\n",
       " 'S-of_INS_ONLY',\n",
       " 'S-–_INS_ONLY',\n",
       " 'S-because_INS',\n",
       " 'S-after_INS',\n",
       " 'B-to_INS',\n",
       " 'E-to_INS',\n",
       " 'B-of_INS',\n",
       " 'E-of_INS',\n",
       " 'I-to_INS',\n",
       " 'I-of_INS']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of entities for NER\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting labels to integer and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2int = {lab: i for i, lab in enumerate(all_labels)}\n",
    "int2lab = {i: lab for i, lab in enumerate(all_labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [[i] for i,_ in enumerate(all_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = OneHotEncoder(handle_unknown='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='error', sparse=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.fit(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/gpuadmin/projects/candice/AGEL/agel_backend/agel_v15/copy_editing/get_grammar_suggestions')\n",
    "from __parameters__ import word_tokenizer, sentence_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_float = 'float32'\n",
    "dtype_int = 'int32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find optimal token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpuadmin/Candice/scripts/venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [len(word_tokenizer.tokenize(item['text'])) for item in data]\n",
    "plt.hist(x, 20, facecolor='g', alpha=0.75, cumulative=True, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8810531750129066"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 50\n",
    "min_len = 7\n",
    "len([item for item in data if min_len < len(word_tokenizer.tokenize(item['text'])) < max_len])/ len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all padded tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 407 ms, sys: 4.31 ms, total: 412 ms\n",
      "Wall time: 410 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequences = [tok2int(word_tokenizer.tokenize(item['text'])) for item in data]\n",
    "all_padded_toks = pad_sequences(sequences, maxlen=max_len, dtype=dtype_int, \n",
    "              padding='post',\n",
    "              truncating='post',\n",
    "              value=vocab2int['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19370, 50)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_padded_toks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all padded and one hot converted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[lab2int[ele] for ele in item['model_output']] for item in data]\n",
    "all_padded_labels = pad_sequences(sequences, maxlen=max_len, dtype=dtype_int, \n",
    "              padding='post',\n",
    "              truncating='post',\n",
    "              value=lab2int['<pad>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Convert to One Hot </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.4 s, sys: 81.9 ms, total: 5.49 s\n",
      "Wall time: 5.48 s\n"
     ]
    }
   ],
   "source": [
    "%time all_one_hot_labels = np.array([label_encoder.transform([[lab] for lab in padded_lab]).toarray() for padded_lab in all_padded_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19370, 50, 23)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_one_hot_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>use indices as maps for training and validation data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data = 17433\n",
      "Length of validation data = 1937\n"
     ]
    }
   ],
   "source": [
    "val_size = 0.1\n",
    "train_idxs, val_idxs, _, _ = train_test_split(\n",
    "    [idx for idx, _ in enumerate(data)], [None]*len(data), test_size=val_size, random_state=random_state)\n",
    "print('Length of training data = {}'.format(len(train_idxs)))\n",
    "print('Length of validation data = {}'.format(len(val_idxs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = np.take(all_padded_toks, train_idxs, axis=0)\n",
    "train_labels = np.take(all_one_hot_labels, train_idxs, axis=0)\n",
    "#train_labels = np.array([all_padded_labels[idx] for idx in train_idxs])\n",
    "\n",
    "val_tokens = np.take(all_padded_toks, val_idxs, axis=0)\n",
    "val_labels = np.take(all_one_hot_labels, val_idxs, axis=0)\n",
    "#val_labels = np.array([all_padded_labels[idx] for idx in val_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17433"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import sgd\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(Callback):\n",
    "    \"\"\"Learning rate scheduler.\n",
    "    # Arguments\n",
    "        schedule: a function that takes an epoch index as input\n",
    "            (integer, indexed from 0) and current learning rate\n",
    "            and returns a new learning rate as output (float).\n",
    "        verbose: int. 0: quiet, 1: update messages.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, schedule, verbose=0):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "        self.verbose = verbose\n",
    "        self._losses = {'val':[], 'train': []}\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        lr = float(K.get_value(self.model.optimizer.lr))\n",
    "        try:  # new API\n",
    "            lr = self.schedule(epoch, lr, self._losses)\n",
    "        except TypeError:  # old API for backward compatibility\n",
    "            lr = self.schedule(epoch)\n",
    "        if not isinstance(lr, (float, np.float32, np.float64)):\n",
    "            raise ValueError('The output of the \"schedule\" function '\n",
    "                             'should be float.')\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        if self.verbose > 0:\n",
    "            print('\\nEpoch %05d: LearningRateScheduler setting learning '\n",
    "                  'rate to %s.' % (epoch + 1, lr))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "        self._losses['val'].append(logs['val_loss'])\n",
    "        self._losses['train'].append(logs['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dim = all_vectors.shape[1]\n",
    "pre_rnn_dropout = 0.33\n",
    "rnn_dropout = 0.33\n",
    "rnn_units = 4\n",
    "epochs = 100\n",
    "lr = 0.5\n",
    "momentum = 0.9\n",
    "decay_rate = 0.9\n",
    "decay_step = int(epochs*0.2)\n",
    "cycle_step = int(epochs*0.1)\n",
    "cycle_rate = 0.9\n",
    "\n",
    "optimizer = sgd(lr=lr, momentum=momentum)\n",
    "\n",
    "def step_decay(epoch, lr, rates):\n",
    "    \n",
    "    ## 0th epoch\n",
    "    if not epoch:\n",
    "        return lr\n",
    "        \n",
    "    if epoch % decay_step == 0:\n",
    "        return lr * decay_rate\n",
    "    \n",
    "    if epoch > 50:\n",
    "        ## cycle lr\n",
    "        if (epoch-50) % cycle_step < cycle_step//2:\n",
    "            return lr * cycle_rate\n",
    "        elif (epoch-50) % cycle_step > cycle_step//2:\n",
    "            return lr / cycle_rate\n",
    "\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in = Input(shape=(max_len,), name='token_inputs')\n",
    "model = None\n",
    "model = Embedding(input_dim = len(all_vocab), \n",
    "                     output_dim = word_embedding_dim,\n",
    "                     input_length = max_len, \n",
    "                     mask_zero=False,\n",
    "                     weights=[all_vectors],\n",
    "                 name='word_embeddings', \n",
    "                 trainable = False)(word_in)\n",
    "# model = SpatialDropout1D(pre_rnn_dropout, name='pre_rnn_dropout')(model)\n",
    "model = LSTM(units=rnn_units, return_sequences=True,\n",
    "#                                recurrent_dropout=rnn_dropout,\n",
    "                               name='LSTM_cell')(model)\n",
    "\n",
    "model = LSTM(units=rnn_units, return_sequences=True,\n",
    "#                                recurrent_dropout=rnn_dropout,\n",
    "                               name='LSTM_cell2')(model)\n",
    "\n",
    "model = TimeDistributed(Dense(len(all_labels), activation=\"softmax\"),  name='label_prediction')(model)\n",
    "model = Model(inputs=[word_in], outputs=[model], name='PrepositionsNER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get intermediate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# get_output = lambda inp_, out_ :K.function([inp_], [out_])\n",
    "# layer_output = get_output(model.layers[0].input, model.layers[-1].output)(val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PrepositionsNER\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "token_inputs (InputLayer)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "word_embeddings (Embedding)  (None, 50, 128)           5549056   \n",
      "_________________________________________________________________\n",
      "LSTM_cell (LSTM)             (None, 50, 4)             2128      \n",
      "_________________________________________________________________\n",
      "LSTM_cell2 (LSTM)            (None, 50, 4)             144       \n",
      "_________________________________________________________________\n",
      "label_prediction (TimeDistri (None, 50, 23)            115       \n",
      "=================================================================\n",
      "Total params: 5,551,443\n",
      "Trainable params: 2,387\n",
      "Non-trainable params: 5,549,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45795"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9159*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from seqeval.metrics import f1_score, classification_report, precision_score, recall_score\n",
    "\n",
    "\n",
    "class F1Metrics(Callback):\n",
    "\n",
    "    def __init__(self, id2label, pad_value=0, validation_data=None, digits=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            id2label (dict): id to label mapping.\n",
    "            (e.g. {1: 'B-LOC', 2: 'I-LOC'})\n",
    "            pad_value (int): padding value.\n",
    "            digits (int or None): number of digits in printed classification report\n",
    "              (use None to print only F1 score without a report).\n",
    "        \"\"\"\n",
    "        super(F1Metrics, self).__init__()\n",
    "        self.id2label = id2label\n",
    "        self.pad_value = pad_value\n",
    "        self.validation_data = validation_data\n",
    "        self.digits = digits\n",
    "        self.is_fit = validation_data is None\n",
    "\n",
    "    def convert_idx_to_name(self, y, array_indexes):\n",
    "        \"\"\"Convert label index to name.\n",
    "        Args:\n",
    "            y (np.ndarray): label index 2d array.\n",
    "            array_indexes (list): list of valid index arrays for each row.\n",
    "        Returns:\n",
    "            y: label name list.\n",
    "        \"\"\"\n",
    "        y = [[self.id2label[idx] for idx in row[row_indexes]] for\n",
    "             row, row_indexes in zip(y, array_indexes)]\n",
    "        return y\n",
    "\n",
    "    def predict(self, X, y):\n",
    "        \"\"\"Predict sequences.\n",
    "        Args:\n",
    "            X (np.ndarray): input data.\n",
    "            y (np.ndarray): tags.\n",
    "        Returns:\n",
    "            y_true: true sequences.\n",
    "            y_pred: predicted sequences.\n",
    "        \"\"\"\n",
    "        y_pred = self.model.predict_on_batch(X)\n",
    "\n",
    "        # reduce dimension.\n",
    "        y_true = np.argmax(y, -1)\n",
    "        y_pred = np.argmax(y_pred, -1)\n",
    "\n",
    "        non_pad_indexes = [np.nonzero(y_true_row != self.pad_value)[0] for y_true_row in y_true]\n",
    "\n",
    "        y_true = self.convert_idx_to_name(y_true, non_pad_indexes)\n",
    "        y_pred = self.convert_idx_to_name(y_pred, non_pad_indexes)\n",
    "\n",
    "        return y_true, y_pred\n",
    "\n",
    "    def score(self, y_true, y_pred):\n",
    "        \"\"\"Calculate f1 score.\n",
    "        Args:\n",
    "            y_true (list): true sequences.\n",
    "            y_pred (list): predicted sequences.\n",
    "        Returns:\n",
    "            score: f1 score.\n",
    "        \"\"\"\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        if self.digits:\n",
    "            print(classification_report(y_true, y_pred, digits=self.digits))\n",
    "        return f1, precision, recall\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if self.is_fit:\n",
    "            self.on_epoch_end_fit(epoch, logs)\n",
    "        else:\n",
    "            self.on_epoch_end_fit_generator(epoch, logs)\n",
    "\n",
    "    def on_epoch_end_fit(self, epoch, logs={}):\n",
    "        X = self.validation_data[0]\n",
    "        y = self.validation_data[1]\n",
    "        y_true, y_pred = self.predict(X, y)\n",
    "        f1, precision, recall = self.score(y_true, y_pred)\n",
    "        logs['val_f1'] = f1\n",
    "        logs['val_precision'] = precision\n",
    "        logs['val_recall'] = recall\n",
    "        #y_true, y_pred = self.predict(train_tokens, train_labels)\n",
    "        #f1, prec, rec = self.score(y_true, y_pred)\n",
    "        #logs['f1'] = f1\n",
    "        #logs['precision'] = prec\n",
    "        #logs['recall'] = rec\n",
    "\n",
    "    def on_epoch_end_fit_generator(self, epoch, logs={}):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for X, y in self.validation_data:\n",
    "            y_true_batch, y_pred_batch = self.predict(X, y)\n",
    "            y_true.extend(y_true_batch)\n",
    "            y_pred.extend(y_pred_batch)\n",
    "        score = self.score(y_true, y_pred)\n",
    "        logs['f1'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "tensorboard = TrainValTensorBoard(log_dir=\"/home/gpuadmin/Candice/tensorboard_logs/prep_ner/{}\".format(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())))\n",
    "\n",
    "callbacks = [F1Metrics(int2lab), lr_scheduler, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-07 12:28:25,193 From /home/gpuadmin/Candice/scripts/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2020-01-07 12:28:26,004 From /home/gpuadmin/Candice/scripts/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2020-01-07 12:28:26,024 From /home/gpuadmin/Candice/scripts/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17433 samples, validate on 1937 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-07 12:28:26,343 From /home/gpuadmin/Candice/scripts/venv/lib/python3.6/site-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17433/17433 [==============================] - 47s 3ms/step - loss: 0.2064 - acc: 0.9598 - val_loss: 0.0840 - val_acc: 0.9773\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.0000    0.0000    0.0000       595\n",
      "     to_INS     0.0000    0.0000    0.0000       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.0000    0.0000    0.0000       366\n",
      "       _INS     0.0000    0.0000    0.0000       286\n",
      "      —_INS     0.0000    0.0000    0.0000       151\n",
      "  after_INS     0.0000    0.0000    0.0000       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.0000    0.0000    0.0000      2134\n",
      "  macro avg     0.0000    0.0000    0.0000      2134\n",
      "\n",
      "Epoch 2/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0707 - acc: 0.9811 - val_loss: 0.0662 - val_acc: 0.9823\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.7130    0.9059    0.7979       595\n",
      "     to_INS     0.0000    0.0000    0.0000       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.0152    0.0191    0.0169       366\n",
      "       _INS     0.0000    0.0000    0.0000       286\n",
      "      —_INS     0.0000    0.0000    0.0000       151\n",
      "  after_INS     0.0000    0.0000    0.0000       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.3850    0.2559    0.3074      2134\n",
      "  macro avg     0.2014    0.2559    0.2254      2134\n",
      "\n",
      "Epoch 3/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0607 - acc: 0.9832 - val_loss: 0.0603 - val_acc: 0.9834\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.6926    0.9429    0.7986       595\n",
      "     to_INS     0.2023    0.3152    0.2465       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.0000    0.0000    0.0000       366\n",
      "       _INS     0.0000    0.0000    0.0000       286\n",
      "      —_INS     0.0000    0.0000    0.0000       151\n",
      "  after_INS     0.0000    0.0000    0.0000       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.4754    0.3037    0.3706      2134\n",
      "  macro avg     0.2193    0.3037    0.2545      2134\n",
      "\n",
      "Epoch 4/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0562 - acc: 0.9838 - val_loss: 0.0560 - val_acc: 0.9838\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.8092    0.9479    0.8731       595\n",
      "     to_INS     0.1991    0.3261    0.2473       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.0000    0.0000    0.0000       366\n",
      "       _INS     0.0083    0.0035    0.0049       286\n",
      "      —_INS     0.0000    0.0000    0.0000       151\n",
      "  after_INS     0.0000    0.0000    0.0000       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.5153    0.3069    0.3847      2134\n",
      "  macro avg     0.2525    0.3069    0.2761      2134\n",
      "\n",
      "Epoch 5/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0525 - acc: 0.9846 - val_loss: 0.0547 - val_acc: 0.9860\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9203    0.9311    0.9256       595\n",
      "     to_INS     0.3101    0.7246    0.4343       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3579    0.0929    0.1475       366\n",
      "       _INS     0.3443    0.2552    0.2932       286\n",
      "      —_INS     1.0000    0.0066    0.0132       151\n",
      "  after_INS     0.8917    0.9032    0.8974       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.5849    0.4695    0.5209      2134\n",
      "  macro avg     0.5398    0.4695    0.4450      2134\n",
      "\n",
      "Epoch 6/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0493 - acc: 0.9862 - val_loss: 0.0497 - val_acc: 0.9863\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9288    0.9429    0.9358       595\n",
      "     to_INS     0.0000    0.0000    0.0000       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3125    0.0137    0.0262       366\n",
      "       _INS     0.4046    0.7343    0.5217       286\n",
      "      —_INS     1.0000    0.0066    0.0132       151\n",
      "  after_INS     0.9426    0.7419    0.8303       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7035    0.4180    0.5244      2134\n",
      "  macro avg     0.5060    0.4180    0.3966      2134\n",
      "\n",
      "Epoch 7/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0467 - acc: 0.9868 - val_loss: 0.0483 - val_acc: 0.9869\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9233    0.9311    0.9272       595\n",
      "     to_INS     0.2143    0.0109    0.0207       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3910    0.4016    0.3962       366\n",
      "       _INS     0.4140    0.7832    0.5417       286\n",
      "      —_INS     0.4902    0.3311    0.3953       151\n",
      "  after_INS     0.9600    0.6194    0.7529       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6197    0.5033    0.5555      2134\n",
      "  macro avg     0.5121    0.5033    0.4844      2134\n",
      "\n",
      "Epoch 8/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0450 - acc: 0.9871 - val_loss: 0.0468 - val_acc: 0.9872\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9331    0.9378    0.9355       595\n",
      "     to_INS     0.0000    0.0000    0.0000       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3956    0.3415    0.3666       366\n",
      "       _INS     0.4223    0.9406    0.5829       286\n",
      "      —_INS     0.5000    0.0066    0.0131       151\n",
      "  after_INS     0.9389    0.7935    0.8601       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6390    0.5042    0.5636      2134\n",
      "  macro avg     0.4882    0.5042    0.4652      2134\n",
      "\n",
      "Epoch 9/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0434 - acc: 0.9873 - val_loss: 0.0449 - val_acc: 0.9874\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9442    0.9378    0.9410       595\n",
      "     to_INS     0.0000    0.0000    0.0000       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3966    0.5137    0.4476       366\n",
      "       _INS     0.4058    0.8741    0.5543       286\n",
      "      —_INS     0.3415    0.0927    0.1458       151\n",
      "  after_INS     0.9048    0.9806    0.9412       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6145    0.5445    0.5774      2134\n",
      "  macro avg     0.4755    0.5445    0.4921      2134\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0425 - acc: 0.9875 - val_loss: 0.0442 - val_acc: 0.9874\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9416    0.9479    0.9447       595\n",
      "     to_INS     0.0000    0.0000    0.0000       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3500    0.1339    0.1937       366\n",
      "       _INS     0.4375    0.8077    0.5676       286\n",
      "      —_INS     0.5500    0.3642    0.4382       151\n",
      "  after_INS     0.9295    0.9355    0.9325       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.0000    0.0000    0.0000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6850    0.4892    0.5708      2134\n",
      "  macro avg     0.4876    0.4892    0.4714      2134\n",
      "\n",
      "Epoch 11/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0414 - acc: 0.9878 - val_loss: 0.0434 - val_acc: 0.9880\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9360    0.9580    0.9468       595\n",
      "     to_INS     0.5000    0.0036    0.0072       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3821    0.1284    0.1922       366\n",
      "       _INS     0.4975    0.6958    0.5802       286\n",
      "      —_INS     0.5806    0.8344    0.6848       151\n",
      "  after_INS     0.9290    0.9290    0.9290       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8400    0.1780    0.2937       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7237    0.5192    0.6046      2134\n",
      "  macro avg     0.6129    0.5192    0.5078      2134\n",
      "\n",
      "Epoch 12/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0405 - acc: 0.9885 - val_loss: 0.0421 - val_acc: 0.9889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9388    0.9546    0.9467       595\n",
      "     to_INS     0.4775    0.1920    0.2739       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4045    0.4863    0.4417       366\n",
      "       _INS     0.5113    0.7098    0.5944       286\n",
      "      —_INS     0.7123    0.6887    0.7003       151\n",
      "  after_INS     0.8941    0.9806    0.9354       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.9111    0.3475    0.5031       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6787    0.6087    0.6418      2134\n",
      "  macro avg     0.6272    0.6087    0.6001      2134\n",
      "\n",
      "Epoch 13/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0397 - acc: 0.9888 - val_loss: 0.0420 - val_acc: 0.9882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9408    0.9345    0.9376       595\n",
      "     to_INS     0.0000    0.0000    0.0000       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3709    0.1530    0.2166       366\n",
      "       _INS     0.5175    0.8287    0.6371       286\n",
      "      —_INS     0.7000    0.7417    0.7203       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8125    0.1102    0.1940       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7313    0.5267    0.6124      2134\n",
      "  macro avg     0.5574    0.5267    0.5146      2134\n",
      "\n",
      "Epoch 14/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0389 - acc: 0.9888 - val_loss: 0.0408 - val_acc: 0.9888\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9371    0.9513    0.9441       595\n",
      "     to_INS     1.0000    0.0072    0.0144       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3987    0.3388    0.3663       366\n",
      "       _INS     0.5189    0.8147    0.6340       286\n",
      "      —_INS     0.6868    0.8278    0.7508       151\n",
      "  after_INS     0.9295    0.9355    0.9325       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8727    0.4068    0.5549       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7067    0.5825    0.6386      2134\n",
      "  macro avg     0.6929    0.5825    0.5644      2134\n",
      "\n",
      "Epoch 15/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0382 - acc: 0.9889 - val_loss: 0.0403 - val_acc: 0.9889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9421    0.9563    0.9491       595\n",
      "     to_INS     1.0000    0.0072    0.0144       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3979    0.5273    0.4536       366\n",
      "       _INS     0.5213    0.8147    0.6357       286\n",
      "      —_INS     0.6667    0.8344    0.7412       151\n",
      "  after_INS     0.9241    0.9419    0.9329       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8772    0.4237    0.5714       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6792    0.6181    0.6472      2134\n",
      "  macro avg     0.6929    0.6181    0.5813      2134\n",
      "\n",
      "Epoch 16/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0375 - acc: 0.9890 - val_loss: 0.0400 - val_acc: 0.9889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9213    0.9647    0.9425       595\n",
      "     to_INS     1.0000    0.0072    0.0144       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3982    0.3579    0.3770       366\n",
      "       _INS     0.4868    0.8392    0.6162       286\n",
      "      —_INS     0.6684    0.8411    0.7449       151\n",
      "  after_INS     0.9102    0.9806    0.9441       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6855    0.5984    0.6390      2134\n",
      "  macro avg     0.6810    0.5984    0.5650      2134\n",
      "\n",
      "Epoch 17/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0371 - acc: 0.9890 - val_loss: 0.0392 - val_acc: 0.9891\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9375    0.9580    0.9476       595\n",
      "     to_INS     1.0000    0.0072    0.0144       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3972    0.4645    0.4282       366\n",
      "       _INS     0.5301    0.8322    0.6476       286\n",
      "      —_INS     0.6788    0.8675    0.7616       151\n",
      "  after_INS     0.9245    0.9484    0.9363       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6897    0.6134    0.6493      2134\n",
      "  macro avg     0.6929    0.6134    0.5801      2134\n",
      "\n",
      "Epoch 18/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0366 - acc: 0.9890 - val_loss: 0.0395 - val_acc: 0.9887\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9459    0.9395    0.9427       595\n",
      "     to_INS     0.6667    0.0072    0.0143       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3333    0.1475    0.2045       366\n",
      "       _INS     0.5369    0.8147    0.6472       286\n",
      "      —_INS     0.6802    0.8874    0.7701       151\n",
      "  after_INS     0.9290    0.9290    0.9290       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7352    0.5515    0.6303      2134\n",
      "  macro avg     0.6425    0.5515    0.5403      2134\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0361 - acc: 0.9891 - val_loss: 0.0386 - val_acc: 0.9892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9258    0.9647    0.9449       595\n",
      "     to_INS     1.0000    0.0072    0.0144       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4162    0.4208    0.4185       366\n",
      "       _INS     0.5324    0.8322    0.6494       286\n",
      "      —_INS     0.6717    0.8808    0.7622       151\n",
      "  after_INS     0.9264    0.9742    0.9497       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8596    0.4153    0.5600       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7006    0.6097    0.6520      2134\n",
      "  macro avg     0.6926    0.6097    0.5780      2134\n",
      "\n",
      "Epoch 20/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0359 - acc: 0.9891 - val_loss: 0.0386 - val_acc: 0.9891\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9013    0.9664    0.9327       595\n",
      "     to_INS     0.5862    0.0616    0.1115       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4155    0.4836    0.4470       366\n",
      "       _INS     0.5409    0.8322    0.6556       286\n",
      "      —_INS     0.6570    0.9007    0.7598       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6856    0.6293    0.6562      2134\n",
      "  macro avg     0.6328    0.6293    0.5933      2134\n",
      "\n",
      "Epoch 21/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0354 - acc: 0.9892 - val_loss: 0.0381 - val_acc: 0.9891\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9375    0.9580    0.9476       595\n",
      "     to_INS     0.0000    0.0000    0.0000       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4017    0.5137    0.4508       366\n",
      "       _INS     0.5342    0.8182    0.6464       286\n",
      "      —_INS     0.6650    0.8940    0.7627       151\n",
      "  after_INS     0.9367    0.9548    0.9457       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8909    0.4153    0.5665       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6860    0.6204    0.6516      2134\n",
      "  macro avg     0.5662    0.6204    0.5822      2134\n",
      "\n",
      "Epoch 22/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0351 - acc: 0.9892 - val_loss: 0.0382 - val_acc: 0.9891\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9376    0.9597    0.9485       595\n",
      "     to_INS     0.0000    0.0000    0.0000       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4030    0.5219    0.4548       366\n",
      "       _INS     0.5310    0.8077    0.6408       286\n",
      "      —_INS     0.6429    0.8940    0.7479       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6821    0.6223    0.6508      2134\n",
      "  macro avg     0.5626    0.6223    0.5818      2134\n",
      "\n",
      "Epoch 23/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0349 - acc: 0.9892 - val_loss: 0.0375 - val_acc: 0.9891\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9331    0.9613    0.9470       595\n",
      "     to_INS     0.4615    0.0217    0.0415       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4046    0.4809    0.4395       366\n",
      "       _INS     0.5341    0.7937    0.6385       286\n",
      "      —_INS     0.6587    0.9073    0.7632       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8548    0.4492    0.5889       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6891    0.6190    0.6522      2134\n",
      "  macro avg     0.6224    0.6190    0.5859      2134\n",
      "\n",
      "Epoch 24/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0347 - acc: 0.9893 - val_loss: 0.0371 - val_acc: 0.9894\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9330    0.9597    0.9461       595\n",
      "     to_INS     0.3929    0.0399    0.0724       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4474    0.4071    0.4263       366\n",
      "       _INS     0.5351    0.8252    0.6492       286\n",
      "      —_INS     0.6538    0.9007    0.7577       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8750    0.4153    0.5632       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7082    0.6106    0.6558      2134\n",
      "  macro avg     0.6218    0.6106    0.5872      2134\n",
      "\n",
      "Epoch 25/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0344 - acc: 0.9893 - val_loss: 0.0374 - val_acc: 0.9888\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9345    0.9597    0.9469       595\n",
      "     to_INS     0.3498    0.3841    0.3661       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.3304    0.1011    0.1548       366\n",
      "       _INS     0.5385    0.8077    0.6462       286\n",
      "      —_INS     0.6617    0.8808    0.7557       151\n",
      "  after_INS     0.9351    0.9290    0.9320       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6815    0.5975    0.6367      2134\n",
      "  macro avg     0.5974    0.5975    0.5784      2134\n",
      "\n",
      "Epoch 26/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0342 - acc: 0.9894 - val_loss: 0.0372 - val_acc: 0.9894\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9331    0.9613    0.9470       595\n",
      "     to_INS     0.5893    0.1196    0.1988       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4378    0.5000    0.4668       366\n",
      "       _INS     0.5282    0.8182    0.6420       286\n",
      "      —_INS     0.6408    0.8742    0.7395       151\n",
      "  after_INS     0.9363    0.9484    0.9423       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8667    0.4407    0.5843       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6928    0.6340    0.6621      2134\n",
      "  macro avg     0.6435    0.6340    0.6089      2134\n",
      "\n",
      "Epoch 27/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0340 - acc: 0.9894 - val_loss: 0.0371 - val_acc: 0.9894\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9315    0.9597    0.9454       595\n",
      "     to_INS     0.4539    0.2319    0.3070       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4493    0.3388    0.3863       366\n",
      "       _INS     0.5345    0.8392    0.6531       286\n",
      "      —_INS     0.6616    0.8675    0.7507       151\n",
      "  after_INS     0.9367    0.9548    0.9457       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8772    0.4237    0.5714       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7019    0.6223    0.6597      2134\n",
      "  macro avg     0.6305    0.6223    0.6105      2134\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.0368 - val_acc: 0.9894\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9343    0.9563    0.9452       595\n",
      "     to_INS     0.5126    0.2210    0.3089       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4528    0.3934    0.4211       366\n",
      "       _INS     0.5289    0.8007    0.6370       286\n",
      "      —_INS     0.6419    0.9139    0.7541       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8750    0.4153    0.5632       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7014    0.6284    0.6629      2134\n",
      "  macro avg     0.6368    0.6284    0.6148      2134\n",
      "\n",
      "Epoch 29/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0336 - acc: 0.9895 - val_loss: 0.0369 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9288    0.9647    0.9464       595\n",
      "     to_INS     0.5225    0.4203    0.4659       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.5276    0.2869    0.3717       366\n",
      "       _INS     0.5935    0.6434    0.6174       286\n",
      "      —_INS     0.6701    0.8742    0.7586       151\n",
      "  after_INS     0.9296    0.8516    0.8889       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8667    0.4407    0.5843       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7408    0.6068    0.6672      2134\n",
      "  macro avg     0.6594    0.6068    0.6212      2134\n",
      "\n",
      "Epoch 30/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0336 - acc: 0.9894 - val_loss: 0.0366 - val_acc: 0.9894\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9317    0.9630    0.9471       595\n",
      "     to_INS     0.4901    0.2681    0.3466       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4356    0.3607    0.3946       366\n",
      "       _INS     0.5371    0.8357    0.6539       286\n",
      "      —_INS     0.6618    0.9073    0.7654       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6989    0.6364    0.6662      2134\n",
      "  macro avg     0.6324    0.6364    0.6201      2134\n",
      "\n",
      "Epoch 31/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0334 - acc: 0.9895 - val_loss: 0.0363 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9357    0.9546    0.9451       595\n",
      "     to_INS     0.4841    0.4964    0.4902       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4842    0.2514    0.3309       366\n",
      "       _INS     0.5886    0.6154    0.6017       286\n",
      "      —_INS     0.6633    0.8609    0.7493       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8772    0.4237    0.5714       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7269    0.6111    0.6640      2134\n",
      "  macro avg     0.6486    0.6111    0.6181      2134\n",
      "\n",
      "Epoch 32/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0332 - acc: 0.9897 - val_loss: 0.0362 - val_acc: 0.9895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9243    0.9647    0.9441       595\n",
      "     to_INS     0.6316    0.1304    0.2162       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4375    0.4590    0.4480       366\n",
      "       _INS     0.5315    0.8252    0.6466       286\n",
      "      —_INS     0.6618    0.8940    0.7606       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6999    0.6340    0.6654      2134\n",
      "  macro avg     0.6482    0.6340    0.6104      2134\n",
      "\n",
      "Epoch 33/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0331 - acc: 0.9895 - val_loss: 0.0375 - val_acc: 0.9890\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9469    0.9294    0.9381       595\n",
      "     to_INS     0.4925    0.2391    0.3220       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4169    0.4044    0.4105       366\n",
      "       _INS     0.5390    0.7972    0.6432       286\n",
      "      —_INS     0.6615    0.8543    0.7457       151\n",
      "  after_INS     0.9392    0.8968    0.9175       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8667    0.4407    0.5843       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6925    0.6162    0.6521      2134\n",
      "  macro avg     0.6344    0.6162    0.6115      2134\n",
      "\n",
      "Epoch 34/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0329 - acc: 0.9897 - val_loss: 0.0362 - val_acc: 0.9894\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9285    0.9597    0.9438       595\n",
      "     to_INS     0.5612    0.1993    0.2941       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4332    0.4699    0.4509       366\n",
      "       _INS     0.5274    0.8427    0.6487       286\n",
      "      —_INS     0.6633    0.8609    0.7493       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6913    0.6434    0.6665      2134\n",
      "  macro avg     0.6391    0.6434    0.6204      2134\n",
      "\n",
      "Epoch 35/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0328 - acc: 0.9897 - val_loss: 0.0359 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9391    0.9597    0.9493       595\n",
      "     to_INS     0.5299    0.2246    0.3155       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4487    0.4180    0.4328       366\n",
      "       _INS     0.5367    0.8427    0.6558       286\n",
      "      —_INS     0.6634    0.8874    0.7592       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7033    0.6387    0.6694      2134\n",
      "  macro avg     0.6419    0.6387    0.6228      2134\n",
      "\n",
      "Epoch 36/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0327 - acc: 0.9896 - val_loss: 0.0373 - val_acc: 0.9887\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9545    0.9160    0.9348       595\n",
      "     to_INS     0.4101    0.5616    0.4740       276\n",
      "     in_INS     1.0000    0.0111    0.0220        90\n",
      "      –_INS     0.3221    0.2350    0.2717       366\n",
      "       _INS     0.5911    0.6014    0.5962       286\n",
      "      —_INS     0.6617    0.8808    0.7557       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8667    0.4407    0.5843       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6706    0.6068    0.6371      2134\n",
      "  macro avg     0.6582    0.6068    0.6044      2134\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0326 - acc: 0.9897 - val_loss: 0.0358 - val_acc: 0.9892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9360    0.9580    0.9468       595\n",
      "     to_INS     0.4196    0.4819    0.4486       276\n",
      "     in_INS     1.0000    0.0333    0.0645        90\n",
      "      –_INS     0.3943    0.2650    0.3170       366\n",
      "       _INS     0.5638    0.6643    0.6100       286\n",
      "      —_INS     0.6683    0.8808    0.7600       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6874    0.6223    0.6532      2134\n",
      "  macro avg     0.6634    0.6223    0.6157      2134\n",
      "\n",
      "Epoch 38/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0324 - acc: 0.9897 - val_loss: 0.0357 - val_acc: 0.9897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9314    0.9580    0.9445       595\n",
      "     to_INS     0.4957    0.4167    0.4528       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.5201    0.3880    0.4444       366\n",
      "       _INS     0.5623    0.5839    0.5729       286\n",
      "      —_INS     0.6684    0.8543    0.7500       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8667    0.4407    0.5843       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7245    0.6200    0.6682      2134\n",
      "  macro avg     0.6512    0.6200    0.6288      2134\n",
      "\n",
      "Epoch 39/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0322 - acc: 0.9898 - val_loss: 0.0355 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9332    0.9630    0.9479       595\n",
      "     to_INS     0.5319    0.1812    0.2703       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4602    0.4426    0.4513       366\n",
      "       _INS     0.5354    0.8462    0.6558       286\n",
      "      —_INS     0.6683    0.8808    0.7600       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7053    0.6392    0.6706      2134\n",
      "  macro avg     0.6427    0.6392    0.6203      2134\n",
      "\n",
      "Epoch 40/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0322 - acc: 0.9898 - val_loss: 0.0357 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9487    0.9328    0.9407       595\n",
      "     to_INS     0.4931    0.3877    0.4341       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4889    0.4208    0.4523       366\n",
      "       _INS     0.5625    0.6294    0.5941       286\n",
      "      —_INS     0.6649    0.8543    0.7478       151\n",
      "  after_INS     0.9351    0.9290    0.9320       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7161    0.6195    0.6643      2134\n",
      "  macro avg     0.6505    0.6195    0.6290      2134\n",
      "\n",
      "Epoch 41/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0320 - acc: 0.9898 - val_loss: 0.0355 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9329    0.9580    0.9453       595\n",
      "     to_INS     0.5783    0.1739    0.2674       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4938    0.4344    0.4622       366\n",
      "       _INS     0.5298    0.8392    0.6495       286\n",
      "      —_INS     0.6583    0.8675    0.7486       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7151    0.6340    0.6721      2134\n",
      "  macro avg     0.6530    0.6340    0.6198      2134\n",
      "\n",
      "Epoch 42/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0320 - acc: 0.9898 - val_loss: 0.0354 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9411    0.9395    0.9403       595\n",
      "     to_INS     0.4822    0.4420    0.4612       276\n",
      "     in_INS     1.0000    0.0556    0.1053        90\n",
      "      –_INS     0.5376    0.2541    0.3451       366\n",
      "       _INS     0.5714    0.6573    0.6114       286\n",
      "      —_INS     0.6650    0.8675    0.7529       151\n",
      "  after_INS     0.9359    0.9419    0.9389       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7333    0.6068    0.6641      2134\n",
      "  macro avg     0.6985    0.6068    0.6207      2134\n",
      "\n",
      "Epoch 43/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0319 - acc: 0.9898 - val_loss: 0.0359 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9438    0.9311    0.9374       595\n",
      "     to_INS     0.4625    0.2681    0.3394       276\n",
      "     in_INS     0.6486    0.2667    0.3780        90\n",
      "      –_INS     0.5543    0.2650    0.3586       366\n",
      "       _INS     0.5396    0.7622    0.6319       286\n",
      "      —_INS     0.6650    0.8808    0.7578       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8571    0.4576    0.5967       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7294    0.6101    0.6645      2134\n",
      "  macro avg     0.6798    0.6101    0.6225      2134\n",
      "\n",
      "Epoch 44/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0317 - acc: 0.9900 - val_loss: 0.0354 - val_acc: 0.9890\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9343    0.9563    0.9452       595\n",
      "     to_INS     0.3741    0.3986    0.3860       276\n",
      "     in_INS     0.6071    0.1889    0.2881        90\n",
      "      –_INS     0.3302    0.1940    0.2444       366\n",
      "       _INS     0.5394    0.7657    0.6329       286\n",
      "      —_INS     0.6751    0.8808    0.7644       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8667    0.4407    0.5843       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6707    0.6195    0.6441      2134\n",
      "  macro avg     0.6268    0.6195    0.6079      2134\n",
      "\n",
      "Epoch 45/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0317 - acc: 0.9899 - val_loss: 0.0355 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9300    0.9597    0.9446       595\n",
      "     to_INS     0.4841    0.2754    0.3510       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.4783    0.3907    0.4301       366\n",
      "       _INS     0.5426    0.7797    0.6399       286\n",
      "      —_INS     0.6598    0.8477    0.7420       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7078    0.6289    0.6660      2134\n",
      "  macro avg     0.6390    0.6289    0.6220      2134\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0316 - acc: 0.9899 - val_loss: 0.0351 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9315    0.9597    0.9454       595\n",
      "     to_INS     0.5291    0.3297    0.4063       276\n",
      "     in_INS     0.6129    0.2111    0.3140        90\n",
      "      –_INS     0.5330    0.3087    0.3910       366\n",
      "       _INS     0.5745    0.6608    0.6146       286\n",
      "      —_INS     0.6667    0.8609    0.7514       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7417    0.6162    0.6732      2134\n",
      "  macro avg     0.6853    0.6162    0.6334      2134\n",
      "\n",
      "Epoch 47/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0316 - acc: 0.9898 - val_loss: 0.0355 - val_acc: 0.9897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9341    0.9529    0.9434       595\n",
      "     to_INS     0.5326    0.1775    0.2663       276\n",
      "     in_INS     0.0000    0.0000    0.0000        90\n",
      "      –_INS     0.5088    0.3962    0.4455       366\n",
      "       _INS     0.5336    0.8322    0.6503       286\n",
      "      —_INS     0.6632    0.8477    0.7442       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7206    0.6223    0.6678      2134\n",
      "  macro avg     0.6507    0.6223    0.6149      2134\n",
      "\n",
      "Epoch 48/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0315 - acc: 0.9899 - val_loss: 0.0350 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9289    0.9664    0.9473       595\n",
      "     to_INS     0.4631    0.2500    0.3247       276\n",
      "     in_INS     0.6410    0.2778    0.3876        90\n",
      "      –_INS     0.4699    0.3197    0.3805       366\n",
      "       _INS     0.5364    0.8497    0.6576       286\n",
      "      —_INS     0.6734    0.8874    0.7657       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8667    0.4407    0.5843       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7075    0.6392    0.6716      2134\n",
      "  macro avg     0.6616    0.6392    0.6311      2134\n",
      "\n",
      "Epoch 49/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0315 - acc: 0.9899 - val_loss: 0.0351 - val_acc: 0.9895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9318    0.9647    0.9480       595\n",
      "     to_INS     0.4417    0.2609    0.3280       276\n",
      "     in_INS     0.6000    0.0333    0.0632        90\n",
      "      –_INS     0.4427    0.3169    0.3694       366\n",
      "       _INS     0.5307    0.8462    0.6523       286\n",
      "      —_INS     0.6599    0.8609    0.7471       151\n",
      "  after_INS     0.9367    0.9548    0.9457       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6978    0.6275    0.6607      2134\n",
      "  macro avg     0.6522    0.6275    0.6149      2134\n",
      "\n",
      "Epoch 50/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0314 - acc: 0.9899 - val_loss: 0.0352 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9273    0.9647    0.9456       595\n",
      "     to_INS     0.4781    0.4746    0.4764       276\n",
      "     in_INS     0.6429    0.2000    0.3051        90\n",
      "      –_INS     0.4290    0.3552    0.3886       366\n",
      "       _INS     0.5780    0.6608    0.6166       286\n",
      "      —_INS     0.6717    0.8808    0.7622       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6990    0.6453    0.6711      2134\n",
      "  macro avg     0.6618    0.6453    0.6428      2134\n",
      "\n",
      "Epoch 51/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0314 - acc: 0.9899 - val_loss: 0.0358 - val_acc: 0.9895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9411    0.9395    0.9403       595\n",
      "     to_INS     0.5854    0.1739    0.2682       276\n",
      "     in_INS     0.6250    0.0556    0.1020        90\n",
      "      –_INS     0.5326    0.2678    0.3564       366\n",
      "       _INS     0.5446    0.7902    0.6448       286\n",
      "      —_INS     0.6804    0.8742    0.7652       151\n",
      "  after_INS     0.9290    0.9290    0.9290       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7472    0.5928    0.6611      2134\n",
      "  macro avg     0.6925    0.5928    0.6031      2134\n",
      "\n",
      "Epoch 52/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0312 - acc: 0.9900 - val_loss: 0.0351 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9328    0.9563    0.9444       595\n",
      "     to_INS     0.4682    0.3732    0.4153       276\n",
      "     in_INS     0.6765    0.2556    0.3710        90\n",
      "      –_INS     0.4667    0.3634    0.4086       366\n",
      "       _INS     0.5508    0.7203    0.6242       286\n",
      "      —_INS     0.6373    0.8609    0.7324       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7012    0.6401    0.6693      2134\n",
      "  macro avg     0.6638    0.6401    0.6397      2134\n",
      "\n",
      "Epoch 53/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0311 - acc: 0.9900 - val_loss: 0.0349 - val_acc: 0.9901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9352    0.9462    0.9407       595\n",
      "     to_INS     0.5789    0.1993    0.2965       276\n",
      "     in_INS     0.6739    0.3444    0.4559        90\n",
      "      –_INS     0.5258    0.4180    0.4658       366\n",
      "       _INS     0.5442    0.8182    0.6536       286\n",
      "      —_INS     0.6789    0.8543    0.7566       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8025    0.5508    0.6533       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7278    0.6467    0.6849      2134\n",
      "  macro avg     0.6872    0.6467    0.6460      2134\n",
      "\n",
      "Epoch 54/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0310 - acc: 0.9900 - val_loss: 0.0348 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9359    0.9563    0.9460       595\n",
      "     to_INS     0.4819    0.2899    0.3620       276\n",
      "     in_INS     0.6667    0.1111    0.1905        90\n",
      "      –_INS     0.5152    0.3251    0.3987       366\n",
      "       _INS     0.5437    0.8042    0.6488       286\n",
      "      —_INS     0.6771    0.8609    0.7580       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7223    0.6289    0.6723      2134\n",
      "  macro avg     0.6763    0.6289    0.6297      2134\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0308 - acc: 0.9901 - val_loss: 0.0348 - val_acc: 0.9897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9328    0.9563    0.9444       595\n",
      "     to_INS     0.4784    0.4022    0.4370       276\n",
      "     in_INS     0.5455    0.1333    0.2143        90\n",
      "      –_INS     0.4820    0.3661    0.4161       366\n",
      "       _INS     0.5581    0.6888    0.6166       286\n",
      "      —_INS     0.6650    0.8675    0.7529       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7090    0.6359    0.6705      2134\n",
      "  macro avg     0.6653    0.6359    0.6380      2134\n",
      "\n",
      "Epoch 56/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.0349 - val_acc: 0.9901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9329    0.9580    0.9453       595\n",
      "     to_INS     0.5577    0.2101    0.3053       276\n",
      "     in_INS     0.7045    0.3444    0.4627        90\n",
      "      –_INS     0.5102    0.4098    0.4545       366\n",
      "       _INS     0.5469    0.8357    0.6611       286\n",
      "      —_INS     0.6804    0.8742    0.7652       151\n",
      "  after_INS     0.9355    0.9355    0.9355       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8657    0.4915    0.6270       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7256    0.6481    0.6847      2134\n",
      "  macro avg     0.6867    0.6481    0.6459      2134\n",
      "\n",
      "Epoch 57/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0308 - acc: 0.9901 - val_loss: 0.0350 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9374    0.9563    0.9468       595\n",
      "     to_INS     0.6111    0.1594    0.2529       276\n",
      "     in_INS     0.7000    0.2333    0.3500        90\n",
      "      –_INS     0.5135    0.3634    0.4256       366\n",
      "       _INS     0.5430    0.8392    0.6593       286\n",
      "      —_INS     0.6736    0.8609    0.7558       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7344    0.6284    0.6773      2134\n",
      "  macro avg     0.6943    0.6284    0.6284      2134\n",
      "\n",
      "Epoch 58/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0309 - acc: 0.9901 - val_loss: 0.0348 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9328    0.9563    0.9444       595\n",
      "     to_INS     0.4258    0.3225    0.3670       276\n",
      "     in_INS     0.6538    0.1889    0.2931        90\n",
      "      –_INS     0.4699    0.3415    0.3956       366\n",
      "       _INS     0.5464    0.7622    0.6365       286\n",
      "      —_INS     0.6769    0.8742    0.7630       151\n",
      "  after_INS     0.9264    0.9742    0.9497       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8667    0.4407    0.5843       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7018    0.6340    0.6662      2134\n",
      "  macro avg     0.6597    0.6340    0.6316      2134\n",
      "\n",
      "Epoch 59/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0308 - acc: 0.9901 - val_loss: 0.0351 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9442    0.9378    0.9410       595\n",
      "     to_INS     0.4684    0.2681    0.3410       276\n",
      "     in_INS     0.6818    0.3333    0.4478        90\n",
      "      –_INS     0.4943    0.3552    0.4134       366\n",
      "       _INS     0.5503    0.7657    0.6404       286\n",
      "      —_INS     0.6754    0.8543    0.7544       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8730    0.4661    0.6077       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7196    0.6303    0.6720      2134\n",
      "  macro avg     0.6748    0.6303    0.6380      2134\n",
      "\n",
      "Epoch 60/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0309 - acc: 0.9900 - val_loss: 0.0348 - val_acc: 0.9897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9343    0.9563    0.9452       595\n",
      "     to_INS     0.4712    0.3261    0.3854       276\n",
      "     in_INS     0.6667    0.2889    0.4031        90\n",
      "      –_INS     0.4624    0.3361    0.3892       366\n",
      "       _INS     0.5433    0.8112    0.6508       286\n",
      "      —_INS     0.6755    0.8411    0.7493       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8507    0.4831    0.6162       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7052    0.6434    0.6729      2134\n",
      "  macro avg     0.6642    0.6434    0.6402      2134\n",
      "\n",
      "Epoch 61/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0308 - acc: 0.9902 - val_loss: 0.0346 - val_acc: 0.9901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9311    0.9546    0.9427       595\n",
      "     to_INS     0.5290    0.2971    0.3805       276\n",
      "     in_INS     0.6604    0.3889    0.4895        90\n",
      "      –_INS     0.5376    0.4098    0.4651       366\n",
      "       _INS     0.5538    0.7552    0.6391       286\n",
      "      —_INS     0.6825    0.8543    0.7588       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8082    0.5000    0.6178       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7272    0.6509    0.6869      2134\n",
      "  macro avg     0.6830    0.6509    0.6549      2134\n",
      "\n",
      "Epoch 62/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0307 - acc: 0.9901 - val_loss: 0.0349 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9388    0.9546    0.9467       595\n",
      "     to_INS     0.4912    0.4022    0.4422       276\n",
      "     in_INS     0.6500    0.1444    0.2364        90\n",
      "      –_INS     0.5231    0.3716    0.4345       366\n",
      "       _INS     0.5517    0.6713    0.6057       286\n",
      "      —_INS     0.6667    0.8477    0.7464       151\n",
      "  after_INS     0.9412    0.9290    0.9351       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7213    0.6307    0.6730      2134\n",
      "  macro avg     0.6801    0.6307    0.6407      2134\n",
      "\n",
      "Epoch 63/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0305 - acc: 0.9902 - val_loss: 0.0349 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9403    0.9529    0.9466       595\n",
      "     to_INS     0.4531    0.3152    0.3718       276\n",
      "     in_INS     0.6923    0.3000    0.4186        90\n",
      "      –_INS     0.5330    0.3306    0.4081       366\n",
      "       _INS     0.5428    0.7098    0.6152       286\n",
      "      —_INS     0.6736    0.8609    0.7558       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7228    0.6256    0.6707      2134\n",
      "  macro avg     0.6772    0.6256    0.6362      2134\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0305 - acc: 0.9902 - val_loss: 0.0345 - val_acc: 0.9900\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9328    0.9563    0.9444       595\n",
      "     to_INS     0.4966    0.2681    0.3482       276\n",
      "     in_INS     0.6667    0.4000    0.5000        90\n",
      "      –_INS     0.5286    0.4044    0.4582       366\n",
      "       _INS     0.5520    0.7238    0.6263       286\n",
      "      —_INS     0.6806    0.8609    0.7602       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8594    0.4661    0.6044       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7264    0.6406    0.6808      2134\n",
      "  macro avg     0.6804    0.6406    0.6477      2134\n",
      "\n",
      "Epoch 65/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0303 - acc: 0.9903 - val_loss: 0.0344 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9315    0.9597    0.9454       595\n",
      "     to_INS     0.4744    0.3696    0.4155       276\n",
      "     in_INS     0.6923    0.3000    0.4186        90\n",
      "      –_INS     0.4964    0.3743    0.4268       366\n",
      "       _INS     0.5514    0.7133    0.6220       286\n",
      "      —_INS     0.6825    0.8543    0.7588       151\n",
      "  after_INS     0.9299    0.9419    0.9359       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7127    0.6406    0.6747      2134\n",
      "  macro avg     0.6729    0.6406    0.6451      2134\n",
      "\n",
      "Epoch 66/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0303 - acc: 0.9903 - val_loss: 0.0345 - val_acc: 0.9900\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9372    0.9529    0.9450       595\n",
      "     to_INS     0.4924    0.4674    0.4796       276\n",
      "     in_INS     0.6923    0.4000    0.5070        90\n",
      "      –_INS     0.4909    0.3689    0.4212       366\n",
      "       _INS     0.5847    0.6399    0.6110       286\n",
      "      —_INS     0.6754    0.8543    0.7544       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7196    0.6471    0.6815      2134\n",
      "  macro avg     0.6802    0.6471    0.6559      2134\n",
      "\n",
      "Epoch 67/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0304 - acc: 0.9902 - val_loss: 0.0347 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9359    0.9563    0.9460       595\n",
      "     to_INS     0.4759    0.5725    0.5197       276\n",
      "     in_INS     0.6939    0.3778    0.4892        90\n",
      "      –_INS     0.4548    0.3716    0.4090       366\n",
      "       _INS     0.6052    0.5734    0.5889       286\n",
      "      —_INS     0.6845    0.8477    0.7574       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7073    0.6523    0.6787      2134\n",
      "  macro avg     0.6751    0.6523    0.6562      2134\n",
      "\n",
      "Epoch 68/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0305 - acc: 0.9902 - val_loss: 0.0345 - val_acc: 0.9900\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9330    0.9597    0.9461       595\n",
      "     to_INS     0.5000    0.2319    0.3168       276\n",
      "     in_INS     0.7111    0.3556    0.4741        90\n",
      "      –_INS     0.4904    0.3497    0.4083       366\n",
      "       _INS     0.5419    0.8601    0.6649       286\n",
      "      —_INS     0.6769    0.8742    0.7630       151\n",
      "  after_INS     0.9321    0.9742    0.9527       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7179    0.6453    0.6797      2134\n",
      "  macro avg     0.6752    0.6453    0.6398      2134\n",
      "\n",
      "Epoch 69/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0304 - acc: 0.9902 - val_loss: 0.0345 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9357    0.9546    0.9451       595\n",
      "     to_INS     0.4889    0.4783    0.4835       276\n",
      "     in_INS     0.6875    0.2444    0.3607        90\n",
      "      –_INS     0.5139    0.4044    0.4526       366\n",
      "       _INS     0.5897    0.5629    0.5760       286\n",
      "      —_INS     0.6772    0.8477    0.7529       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7239    0.6378    0.6781      2134\n",
      "  macro avg     0.6839    0.6378    0.6508      2134\n",
      "\n",
      "Epoch 70/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0305 - acc: 0.9901 - val_loss: 0.0348 - val_acc: 0.9897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9300    0.9597    0.9446       595\n",
      "     to_INS     0.4545    0.3442    0.3918       276\n",
      "     in_INS     0.6889    0.3444    0.4593        90\n",
      "      –_INS     0.4496    0.3415    0.3882       366\n",
      "       _INS     0.5529    0.8042    0.6553       286\n",
      "      —_INS     0.6891    0.8808    0.7733       151\n",
      "  after_INS     0.9304    0.9484    0.9393       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.7805    0.5424    0.6400       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6997    0.6542    0.6762      2134\n",
      "  macro avg     0.6578    0.6542    0.6461      2134\n",
      "\n",
      "Epoch 71/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0304 - acc: 0.9902 - val_loss: 0.0347 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9415    0.9462    0.9438       595\n",
      "     to_INS     0.5175    0.2681    0.3532       276\n",
      "     in_INS     0.6842    0.2889    0.4062        90\n",
      "      –_INS     0.4837    0.4044    0.4405       366\n",
      "       _INS     0.5598    0.8182    0.6648       286\n",
      "      —_INS     0.6735    0.8742    0.7608       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8529    0.4915    0.6237       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7184    0.6490    0.6819      2134\n",
      "  macro avg     0.6788    0.6490    0.6479      2134\n",
      "\n",
      "Epoch 72/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0304 - acc: 0.9902 - val_loss: 0.0352 - val_acc: 0.9892\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9302    0.9630    0.9463       595\n",
      "     to_INS     0.4221    0.4710    0.4452       276\n",
      "     in_INS     0.7234    0.3778    0.4964        90\n",
      "      –_INS     0.3708    0.2705    0.3128       366\n",
      "       _INS     0.5524    0.7378    0.6317       286\n",
      "      —_INS     0.6825    0.8543    0.7588       151\n",
      "  after_INS     0.9290    0.9290    0.9290       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6780    0.6434    0.6603      2134\n",
      "  macro avg     0.6459    0.6434    0.6346      2134\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0302 - acc: 0.9903 - val_loss: 0.0345 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9375    0.9580    0.9476       595\n",
      "     to_INS     0.6000    0.1848    0.2825       276\n",
      "     in_INS     0.6939    0.3778    0.4892        90\n",
      "      –_INS     0.4583    0.4809    0.4693       366\n",
      "       _INS     0.5448    0.8287    0.6574       286\n",
      "      —_INS     0.6753    0.8675    0.7594       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8052    0.5254    0.6359       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7078    0.6607    0.6835      2134\n",
      "  macro avg     0.6798    0.6607    0.6476      2134\n",
      "\n",
      "Epoch 74/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0301 - acc: 0.9902 - val_loss: 0.0344 - val_acc: 0.9900\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9299    0.9580    0.9437       595\n",
      "     to_INS     0.5029    0.3188    0.3902       276\n",
      "     in_INS     0.7037    0.4222    0.5278        90\n",
      "      –_INS     0.5229    0.3743    0.4363       366\n",
      "       _INS     0.5532    0.7448    0.6349       286\n",
      "      —_INS     0.6806    0.8609    0.7602       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8689    0.4492    0.5922       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7247    0.6453    0.6827      2134\n",
      "  macro avg     0.6816    0.6453    0.6508      2134\n",
      "\n",
      "Epoch 75/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0301 - acc: 0.9904 - val_loss: 0.0345 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9355    0.9513    0.9433       595\n",
      "     to_INS     0.5426    0.2536    0.3457       276\n",
      "     in_INS     0.7045    0.3444    0.4627        90\n",
      "      –_INS     0.5053    0.3907    0.4407       366\n",
      "       _INS     0.5490    0.7832    0.6455       286\n",
      "      —_INS     0.6771    0.8609    0.7580       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7258    0.6401    0.6803      2134\n",
      "  macro avg     0.6847    0.6401    0.6446      2134\n",
      "\n",
      "Epoch 76/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0300 - acc: 0.9904 - val_loss: 0.0347 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9285    0.9597    0.9438       595\n",
      "     to_INS     0.5039    0.4638    0.4830       276\n",
      "     in_INS     0.6981    0.4111    0.5175        90\n",
      "      –_INS     0.4669    0.3852    0.4222       366\n",
      "       _INS     0.5813    0.6748    0.6246       286\n",
      "      —_INS     0.6735    0.8742    0.7608       151\n",
      "  after_INS     0.9392    0.8968    0.9175       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7110    0.6537    0.6812      2134\n",
      "  macro avg     0.6755    0.6537    0.6572      2134\n",
      "\n",
      "Epoch 77/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0346 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9342    0.9546    0.9443       595\n",
      "     to_INS     0.4864    0.4529    0.4690       276\n",
      "     in_INS     0.7059    0.4000    0.5106        90\n",
      "      –_INS     0.4479    0.3880    0.4158       366\n",
      "       _INS     0.5851    0.6608    0.6207       286\n",
      "      —_INS     0.6718    0.8675    0.7572       151\n",
      "  after_INS     0.9281    0.9161    0.9221       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8730    0.4661    0.6077       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7056    0.6504    0.6769      2134\n",
      "  macro avg     0.6716    0.6504    0.6541      2134\n",
      "\n",
      "Epoch 78/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0301 - acc: 0.9903 - val_loss: 0.0344 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9371    0.9513    0.9441       595\n",
      "     to_INS     0.5812    0.2464    0.3461       276\n",
      "     in_INS     0.6842    0.1444    0.2385        90\n",
      "      –_INS     0.4938    0.4344    0.4622       366\n",
      "       _INS     0.5564    0.7762    0.6482       286\n",
      "      —_INS     0.6788    0.8675    0.7616       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7254    0.6364    0.6780      2134\n",
      "  macro avg     0.6880    0.6364    0.6384      2134\n",
      "\n",
      "Epoch 79/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0301 - acc: 0.9902 - val_loss: 0.0345 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9301    0.9613    0.9455       595\n",
      "     to_INS     0.4671    0.2826    0.3521       276\n",
      "     in_INS     0.7234    0.3778    0.4964        90\n",
      "      –_INS     0.4558    0.3525    0.3975       366\n",
      "       _INS     0.5473    0.8287    0.6592       286\n",
      "      —_INS     0.6734    0.8874    0.7657       151\n",
      "  after_INS     0.9304    0.9484    0.9393       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8833    0.4492    0.5955       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7054    0.6485    0.6758      2134\n",
      "  macro avg     0.6658    0.6485    0.6420      2134\n",
      "\n",
      "Epoch 80/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0302 - acc: 0.9902 - val_loss: 0.0344 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9344    0.9580    0.9461       595\n",
      "     to_INS     0.4929    0.2500    0.3317       276\n",
      "     in_INS     0.7222    0.4333    0.5417        90\n",
      "      –_INS     0.4875    0.3743    0.4235       366\n",
      "       _INS     0.5463    0.8252    0.6574       286\n",
      "      —_INS     0.6650    0.8808    0.7578       151\n",
      "  after_INS     0.9317    0.9677    0.9494       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8644    0.4322    0.5763       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7150    0.6490    0.6804      2134\n",
      "  macro avg     0.6741    0.6490    0.6447      2134\n",
      "\n",
      "Epoch 81/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0347 - val_acc: 0.9901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9446    0.9462    0.9454       595\n",
      "     to_INS     0.6173    0.1812    0.2801       276\n",
      "     in_INS     0.6863    0.3889    0.4965        90\n",
      "      –_INS     0.5129    0.3798    0.4364       366\n",
      "       _INS     0.5519    0.8182    0.6592       286\n",
      "      —_INS     0.6788    0.8675    0.7616       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8769    0.4831    0.6230       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7376    0.6364    0.6833      2134\n",
      "  macro avg     0.6983    0.6364    0.6410      2134\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0349 - val_acc: 0.9894\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9369    0.9479    0.9424       595\n",
      "     to_INS     0.4203    0.3152    0.3602       276\n",
      "     in_INS     0.6818    0.5000    0.5769        90\n",
      "      –_INS     0.3947    0.3279    0.3582       366\n",
      "       _INS     0.5428    0.8427    0.6603       286\n",
      "      —_INS     0.6751    0.8808    0.7644       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8750    0.4746    0.6154       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6823    0.6532    0.6675      2134\n",
      "  macro avg     0.6485    0.6532    0.6402      2134\n",
      "\n",
      "Epoch 83/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0347 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9373    0.9546    0.9459       595\n",
      "     to_INS     0.5508    0.2355    0.3299       276\n",
      "     in_INS     0.6964    0.4333    0.5342        90\n",
      "      –_INS     0.5022    0.3169    0.3886       366\n",
      "       _INS     0.5603    0.7308    0.6343       286\n",
      "      —_INS     0.6719    0.8543    0.7522       151\n",
      "  after_INS     0.9299    0.9419    0.9359       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8116    0.4746    0.5989       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7366    0.6223    0.6746      2134\n",
      "  macro avg     0.6831    0.6223    0.6349      2134\n",
      "\n",
      "Epoch 84/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0299 - acc: 0.9904 - val_loss: 0.0346 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9342    0.9546    0.9443       595\n",
      "     to_INS     0.4843    0.2790    0.3540       276\n",
      "     in_INS     0.7111    0.3556    0.4741        90\n",
      "      –_INS     0.4290    0.3880    0.4075       366\n",
      "       _INS     0.5450    0.8252    0.6565       286\n",
      "      —_INS     0.6718    0.8675    0.7572       151\n",
      "  after_INS     0.9304    0.9484    0.9393       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6966    0.6500    0.6725      2134\n",
      "  macro avg     0.6630    0.6500    0.6419      2134\n",
      "\n",
      "Epoch 85/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0298 - acc: 0.9904 - val_loss: 0.0344 - val_acc: 0.9900\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9201    0.9681    0.9435       595\n",
      "     to_INS     0.5252    0.2645    0.3518       276\n",
      "     in_INS     0.6786    0.4222    0.5205        90\n",
      "      –_INS     0.4901    0.4044    0.4431       366\n",
      "       _INS     0.5505    0.8007    0.6524       286\n",
      "      —_INS     0.6788    0.8675    0.7616       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8750    0.4746    0.6154       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7156    0.6556    0.6843      2134\n",
      "  macro avg     0.6749    0.6556    0.6503      2134\n",
      "\n",
      "Epoch 86/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0298 - acc: 0.9904 - val_loss: 0.0343 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9328    0.9563    0.9444       595\n",
      "     to_INS     0.4975    0.3551    0.4144       276\n",
      "     in_INS     0.6981    0.4111    0.5175        90\n",
      "      –_INS     0.4483    0.3907    0.4175       366\n",
      "       _INS     0.5539    0.7902    0.6513       286\n",
      "      —_INS     0.6753    0.8675    0.7594       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8462    0.4661    0.6011       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7019    0.6598    0.6802      2134\n",
      "  macro avg     0.6672    0.6598    0.6533      2134\n",
      "\n",
      "Epoch 87/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0298 - acc: 0.9904 - val_loss: 0.0344 - val_acc: 0.9902\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9328    0.9563    0.9444       595\n",
      "     to_INS     0.5574    0.2464    0.3417       276\n",
      "     in_INS     0.6780    0.4444    0.5369        90\n",
      "      –_INS     0.5120    0.4071    0.4536       366\n",
      "       _INS     0.5563    0.8462    0.6713       286\n",
      "      —_INS     0.6825    0.8543    0.7588       151\n",
      "  after_INS     0.9304    0.9484    0.9393       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.7778    0.5932    0.6731       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7236    0.6626    0.6918      2134\n",
      "  macro avg     0.6820    0.6626    0.6571      2134\n",
      "\n",
      "Epoch 88/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0299 - acc: 0.9904 - val_loss: 0.0344 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9316    0.9613    0.9462       595\n",
      "     to_INS     0.4802    0.3080    0.3753       276\n",
      "     in_INS     0.6508    0.4556    0.5359        90\n",
      "      –_INS     0.4768    0.3087    0.3748       366\n",
      "       _INS     0.5505    0.8392    0.6648       286\n",
      "      —_INS     0.6718    0.8675    0.7572       151\n",
      "  after_INS     0.9313    0.9613    0.9460       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8286    0.4915    0.6170       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7116    0.6509    0.6799      2134\n",
      "  macro avg     0.6658    0.6509    0.6448      2134\n",
      "\n",
      "Epoch 89/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0299 - acc: 0.9903 - val_loss: 0.0344 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9357    0.9546    0.9451       595\n",
      "     to_INS     0.5170    0.3297    0.4027       276\n",
      "     in_INS     0.7200    0.4000    0.5143        90\n",
      "      –_INS     0.4595    0.3716    0.4109       366\n",
      "       _INS     0.5530    0.8566    0.6722       286\n",
      "      —_INS     0.6771    0.8609    0.7580       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.7805    0.5424    0.6400       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7072    0.6645    0.6852      2134\n",
      "  macro avg     0.6697    0.6645    0.6553      2134\n",
      "\n",
      "Epoch 90/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0299 - acc: 0.9903 - val_loss: 0.0347 - val_acc: 0.9900\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9314    0.9580    0.9445       595\n",
      "     to_INS     0.5833    0.3804    0.4605       276\n",
      "     in_INS     0.6852    0.4111    0.5139        90\n",
      "      –_INS     0.5069    0.3005    0.3774       366\n",
      "       _INS     0.5976    0.7063    0.6474       286\n",
      "      —_INS     0.6823    0.8675    0.7638       151\n",
      "  after_INS     0.9396    0.9032    0.9211       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8772    0.4237    0.5714       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7476    0.6303    0.6840      2134\n",
      "  macro avg     0.6961    0.6303    0.6486      2134\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0299 - acc: 0.9903 - val_loss: 0.0347 - val_acc: 0.9896\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9359    0.9563    0.9460       595\n",
      "     to_INS     0.4366    0.3370    0.3804       276\n",
      "     in_INS     0.7091    0.4333    0.5379        90\n",
      "      –_INS     0.4170    0.3087    0.3548       366\n",
      "       _INS     0.5587    0.8322    0.6685       286\n",
      "      —_INS     0.6768    0.8874    0.7679       151\n",
      "  after_INS     0.9290    0.9290    0.9290       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8615    0.4746    0.6120       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6961    0.6495    0.6720      2134\n",
      "  macro avg     0.6567    0.6495    0.6417      2134\n",
      "\n",
      "Epoch 92/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0298 - acc: 0.9903 - val_loss: 0.0343 - val_acc: 0.9901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9315    0.9597    0.9454       595\n",
      "     to_INS     0.5377    0.4130    0.4672       276\n",
      "     in_INS     0.6939    0.3778    0.4892        90\n",
      "      –_INS     0.5279    0.3361    0.4107       366\n",
      "       _INS     0.5817    0.7098    0.6394       286\n",
      "      —_INS     0.6842    0.8609    0.7625       151\n",
      "  after_INS     0.9299    0.9419    0.9359       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7373    0.6443    0.6877      2134\n",
      "  macro avg     0.6911    0.6443    0.6559      2134\n",
      "\n",
      "Epoch 93/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0296 - acc: 0.9904 - val_loss: 0.0343 - val_acc: 0.9900\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9286    0.9613    0.9447       595\n",
      "     to_INS     0.5232    0.2862    0.3700       276\n",
      "     in_INS     0.6774    0.4667    0.5526        90\n",
      "      –_INS     0.4786    0.3661    0.4149       366\n",
      "       _INS     0.5500    0.8462    0.6667       286\n",
      "      —_INS     0.6667    0.8609    0.7514       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8551    0.5000    0.6310       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7130    0.6589    0.6849      2134\n",
      "  macro avg     0.6730    0.6589    0.6516      2134\n",
      "\n",
      "Epoch 94/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0296 - acc: 0.9904 - val_loss: 0.0343 - val_acc: 0.9902\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9329    0.9580    0.9453       595\n",
      "     to_INS     0.5447    0.4638    0.5010       276\n",
      "     in_INS     0.6508    0.4556    0.5359        90\n",
      "      –_INS     0.4929    0.3770    0.4272       366\n",
      "       _INS     0.5906    0.7063    0.6433       286\n",
      "      —_INS     0.6823    0.8675    0.7638       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8710    0.4576    0.6000       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7263    0.6617    0.6925      2134\n",
      "  macro avg     0.6857    0.6617    0.6661      2134\n",
      "\n",
      "Epoch 95/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0295 - acc: 0.9906 - val_loss: 0.0343 - val_acc: 0.9901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9371    0.9513    0.9441       595\n",
      "     to_INS     0.5306    0.2826    0.3688       276\n",
      "     in_INS     0.7368    0.3111    0.4375        90\n",
      "      –_INS     0.5115    0.3661    0.4268       366\n",
      "       _INS     0.5601    0.8147    0.6638       286\n",
      "      —_INS     0.6786    0.8808    0.7666       151\n",
      "  after_INS     0.9308    0.9548    0.9427       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8592    0.5169    0.6455       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7291    0.6471    0.6857      2134\n",
      "  macro avg     0.6869    0.6471    0.6499      2134\n",
      "\n",
      "Epoch 96/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0296 - acc: 0.9904 - val_loss: 0.0344 - val_acc: 0.9900\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9359    0.9563    0.9460       595\n",
      "     to_INS     0.5213    0.3551    0.4224       276\n",
      "     in_INS     0.7000    0.3889    0.5000        90\n",
      "      –_INS     0.4982    0.3798    0.4310       366\n",
      "       _INS     0.5632    0.7168    0.6308       286\n",
      "      —_INS     0.6769    0.8742    0.7630       151\n",
      "  after_INS     0.9304    0.9484    0.9393       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8462    0.4661    0.6011       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7236    0.6467    0.6830      2134\n",
      "  macro avg     0.6811    0.6467    0.6534      2134\n",
      "\n",
      "Epoch 97/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0295 - acc: 0.9905 - val_loss: 0.0346 - val_acc: 0.9897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9360    0.9580    0.9468       595\n",
      "     to_INS     0.4613    0.5181    0.4881       276\n",
      "     in_INS     0.6897    0.4444    0.5405        90\n",
      "      –_INS     0.4179    0.3197    0.3622       366\n",
      "       _INS     0.5873    0.6818    0.6311       286\n",
      "      —_INS     0.6734    0.8874    0.7657       151\n",
      "  after_INS     0.9286    0.9226    0.9256       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.7528    0.5678    0.6473       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6937    0.6603    0.6766      2134\n",
      "  macro avg     0.6568    0.6603    0.6538      2134\n",
      "\n",
      "Epoch 98/100\n",
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0295 - acc: 0.9905 - val_loss: 0.0343 - val_acc: 0.9901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9367    0.9445    0.9406       595\n",
      "     to_INS     0.5411    0.4529    0.4931       276\n",
      "     in_INS     0.6567    0.4889    0.5605        90\n",
      "      –_INS     0.4926    0.3661    0.4201       366\n",
      "       _INS     0.5817    0.7098    0.6394       286\n",
      "      —_INS     0.6856    0.8808    0.7710       151\n",
      "  after_INS     0.9236    0.9355    0.9295       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8636    0.4831    0.6196       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7247    0.6575    0.6894      2134\n",
      "  macro avg     0.6846    0.6575    0.6637      2134\n",
      "\n",
      "Epoch 99/100\n",
      "17433/17433 [==============================] - 44s 3ms/step - loss: 0.0296 - acc: 0.9905 - val_loss: 0.0345 - val_acc: 0.9899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9367    0.9445    0.9406       595\n",
      "     to_INS     0.5427    0.3225    0.4045       276\n",
      "     in_INS     0.6964    0.4333    0.5342        90\n",
      "      –_INS     0.4571    0.3934    0.4229       366\n",
      "       _INS     0.5714    0.7832    0.6608       286\n",
      "      —_INS     0.6735    0.8742    0.7608       151\n",
      "  after_INS     0.9295    0.9355    0.9325       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8158    0.5254    0.6392       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.7146    0.6546    0.6833      2134\n",
      "  macro avg     0.6760    0.6546    0.6551      2134\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17433/17433 [==============================] - 45s 3ms/step - loss: 0.0298 - acc: 0.9904 - val_loss: 0.0344 - val_acc: 0.9898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   with_INS     0.9271    0.9613    0.9439       595\n",
      "     to_INS     0.4828    0.3043    0.3733       276\n",
      "     in_INS     0.6909    0.4222    0.5241        90\n",
      "      –_INS     0.4295    0.3661    0.3953       366\n",
      "       _INS     0.5556    0.8566    0.6740       286\n",
      "      —_INS     0.6602    0.9007    0.7619       151\n",
      "  after_INS     0.9255    0.9613    0.9430       155\n",
      " –_INS_ONLY     0.0000    0.0000    0.0000        32\n",
      "because_INS     0.8529    0.4915    0.6237       118\n",
      "     of_INS     0.0000    0.0000    0.0000        40\n",
      "of_INS_ONLY     0.0000    0.0000    0.0000        13\n",
      "to_INS_ONLY     0.0000    0.0000    0.0000        12\n",
      "\n",
      "  micro avg     0.6962    0.6635    0.6795      2134\n",
      "  macro avg     0.6593    0.6635    0.6486      2134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_tokens,\n",
    "                    y=train_labels,\n",
    "                    validation_data=(val_tokens, val_labels),\n",
    "                    batch_size=64, epochs=epochs, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from joblib import dump, load\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(obj, f)\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "        \n",
    "def save_model(path):\n",
    "    \n",
    "    model.save(path.joinpath(\"model_6_jan.h5\"))\n",
    "    \n",
    "    save_json(vocab2int, path.joinpath('vocab2int.json'))\n",
    "    save_json(int2vocab, path.joinpath('int2vocab.json'))\n",
    "    save_json(lab2int, path.joinpath('lab2int.json'))\n",
    "    save_json(int2lab, path.joinpath('int2lab.json'))\n",
    "    dump(label_encoder, path.joinpath('label_encoder.pkl'))\n",
    "    \n",
    "def load_keras_model(path):\n",
    "    \n",
    "    model = load_model(path.joinpath(\"model.h5\"))\n",
    "    \n",
    "    vocab2int = load_json(path.joinpath('vocab2int.json'))\n",
    "    int2vocab = load_json(path.joinpath('int2vocab.json'))\n",
    "    lab2int = load_json(path.joinpath('lab2int.json'))\n",
    "    int2lab = load_json(path.joinpath('int2lab.json'))\n",
    "    \n",
    "    label_encoder = load(path.joinpath('label_encoder.pkl'))\n",
    "    \n",
    "    return {'model': model,\n",
    "           'vocab2int':vocab2int,\n",
    "           'int2vocab': int2vocab,\n",
    "           'lab2int': lab2int,\n",
    "           'int2lab': int2lab,\n",
    "           'label_encoder': label_encoder}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 11.3 ms, total: 1.27 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "path = Path('/home/gpuadmin/Candice/scripts/temp/PREP_NER')\n",
    "save_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 s, sys: 4.69 s, total: 7.39 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%time loaded_model = load_keras_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'vocab2int', 'int2vocab', 'lab2int', 'int2lab', 'label_encoder'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
